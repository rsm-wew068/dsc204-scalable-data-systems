{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef10b395-190b-4166-b5f2-41610e46cddc",
   "metadata": {},
   "source": [
    "PA 1\n",
    "* For task 2.1 and 3.1, find YOUR CODE HERE and implement.\n",
    "* For task 2.2 and 3.2, find YOUR ANSWER HERE and write your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a2b685-7b9a-4685-a628-96c0b7ae2480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Set up Jupyter Kernel, select Python 3 (ipykernel).\n",
    "# ## Only need to run once.\n",
    "# ## restart the kernel after finishing installation\n",
    "\n",
    "# !pip install \"ray==2.10.0\"\n",
    "# !pip install \"pyarrow==18.1.0\"\n",
    "# !pip install \"modin==0.37.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8247d15f-013e-433d-85fb-98e90d76d9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray: 2.10.0\n",
      "modin: 0.37.0\n"
     ]
    }
   ],
   "source": [
    "## Verify installations:\n",
    "!python -c \"import ray; print('ray:', ray.__version__)\"\n",
    "!python -c \"import modin; print('modin:', modin.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c18a87-8d9d-4fe3-82f2-228a2393fce5",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "#### Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba4f614-1092-4582-ba3e-af33a3be0696",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c95b503016819a678c6c103ab27bd61a",
     "grade": false,
     "grade_id": "cell-14904bc93b5034ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 22:02:02,214\tINFO worker.py:1752 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "# Note: We include only 10M data in the csv file to fit the memory of Datahub.\n",
    "\n",
    "import ray, json, os\n",
    "import time\n",
    "import numpy as np\n",
    "import modin.pandas as pd\n",
    "from modin.utils import reload_modin\n",
    "ray.shutdown()\n",
    "reload_modin()\n",
    "ray.init(num_cpus=4)\n",
    "\n",
    "def run_task2(path):\n",
    "    ## DO NOT MODIFY: START \n",
    "    start_time = time.perf_counter()\n",
    "    raw_df = pd.read_csv(path)\n",
    "    ## DO NOT MODIFY: End \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # Compact vote parsing: normalize missing, convert comma-decimals, remove thousands commas,\n",
    "    # coerce to numeric, fill missing with 0, and clip extreme outliers at the 99th percentile.\n",
    "    v = raw_df['vote'].replace('-', pd.NA).astype(str).str.strip()\n",
    "    v = v.str.replace(r',(?=\\d{1,2}$)', '.', regex=True).str.replace(',', '', regex=False)\n",
    "    v = v.replace({'nan': None, '': None})\n",
    "    # Convert to numeric and keep NaN for missing values so mean() ignores them\n",
    "    raw_df['vote'] = pd.to_numeric(v, errors='coerce')\n",
    "    raw_df['rating_bucket'] = raw_df['overall'].round().astype('Int64')\n",
    "    # Convert unixReviewTime to year\n",
    "    raw_df['reviewYear'] = pd.to_datetime(raw_df['unixReviewTime'], unit='s').dt.year\n",
    "\n",
    "    # Treat missing votes as 0 for the avg_helpful_votes_per_review calculation\n",
    "    raw_df['vote_filled'] = raw_df['vote'].fillna(0.0)\n",
    "    output = raw_df.groupby('rating_bucket').agg(\n",
    "    \tn_reviews=('reviewerID', 'size'),\n",
    "    \tn_unique_reviewers=('reviewerID', 'nunique'),\n",
    "    \tsum_helpful_votes=('vote_filled', 'sum'),\n",
    "    \tearliest_review_year=('reviewYear', 'min')\n",
    "    ).reset_index()\n",
    "    # compute average helpful votes per review using sum / n_reviews (includes missing as zeros)\n",
    "    output['avg_helpful_votes_per_review'] = output['sum_helpful_votes'] / output['n_reviews']\n",
    "    output = output.drop(columns=['sum_helpful_votes'])\n",
    "    \n",
    "    ## DO NOT MODIFY: START \n",
    "    submit = output.describe().round(2)\n",
    "    duration_s = time.perf_counter() - start_time\n",
    "    print(f\"Processing time (excluding file write): {duration_s:.3f} s\")\n",
    "    current_data = json.loads(submit._to_pandas().to_json())\n",
    "    return current_data\n",
    "    ## DO NOT MODIFY: END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "165336e7-f656-465e-850d-60cdf0bc2241",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69eb7e84ca9c7da65a00c5380d7de24a",
     "grade": false,
     "grade_id": "cell-2608234f116dad98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compare_json_files(current_data):\n",
    "        # Load both JSON files\n",
    "    path = os.path.expanduser(\"~/public/origin_results_PA1_task2_1.json\")\n",
    "    with open(path, 'r') as f:\n",
    "        origin_data = json.load(f)\n",
    "        \n",
    "    # Track if any error > 1% exists\n",
    "    has_error_over_1_percent = False\n",
    "    \n",
    "    # Compare each metric\n",
    "    for metric in origin_data.keys():\n",
    "        print(f\"\\n=== Comparing {metric} ===\")\n",
    "        \n",
    "        for stat in origin_data[metric].keys():\n",
    "            origin_val = origin_data[metric][stat]\n",
    "            current_val = current_data[metric][stat]\n",
    "            \n",
    "            # Calculate error percentage\n",
    "            if origin_val != 0:\n",
    "                error_percent = abs(current_val - origin_val) / abs(origin_val) * 100\n",
    "            else:\n",
    "                error_percent = 0 if current_val == 0 else float('inf')\n",
    "            \n",
    "            # Only print if error > 1%\n",
    "            if error_percent > 1.0:\n",
    "                print(f\"  {stat}: {current_val} vs {origin_val} (error: {error_percent:.2f}%)\")\n",
    "                has_error_over_1_percent = True\n",
    "    \n",
    "    # Assert if there exists an error > 1%\n",
    "    assert not has_error_over_1_percent, \"Found errors greater than 1% between the JSON files\"\n",
    "    \n",
    "    if not has_error_over_1_percent:\n",
    "        print(\"\\n✓ All comparisons within 1% tolerance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "046f6370-0043-499a-bbe7-47ff7a4a9170",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26e68e4a863549cdd1e80952b44e6011",
     "grade": true,
     "grade_id": "cell-58b91a1d107d3ac7",
     "locked": true,
     "points": 40,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time (excluding file write): 20.736 s\n",
      "\n",
      "=== Comparing rating_bucket ===\n",
      "\n",
      "=== Comparing n_reviews ===\n",
      "\n",
      "=== Comparing n_unique_reviewers ===\n",
      "\n",
      "=== Comparing avg_helpful_votes_per_review ===\n",
      "\n",
      "=== Comparing earliest_review_year ===\n",
      "\n",
      "✓ All comparisons within 1% tolerance\n"
     ]
    }
   ],
   "source": [
    "raw_dataset_path = \"~/public/modin_dev_dataset_10M_rows.csv\"\n",
    "current_data = run_task2(raw_dataset_path)\n",
    "compare_json_files(current_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501757f-ae1b-4c4c-b6c8-478296d13200",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "caab3e41f1728bc8069ade75b165b69d",
     "grade": false,
     "grade_id": "cell-5e7f49b02bcf9957",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Task 2.2\n",
    "Change the number of CPUs used by Modin or the Ray backend ([documentation here](https://modin.readthedocs.io/en/stable/getting_started/using_modin/using_modin_locally.html#advanced-configuring-the-resources-modin-uses)) on your instance and run your data manipulation code. Document the execution times you see with 1, 2, 3, and 4 CPUs. Is it a linear speedup? If not, why?\n",
    "\n",
    "Note:\n",
    "* We won't check the processing time for Task2. So in your submission, it doesn't matter how many CPUs you set in ray.init(num_cpus=X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e59514e0-08cb-4556-a5a2-0cc26eb8e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Measuring with 1 CPU(s) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 22:06:29,846\tINFO worker.py:1752 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time (excluding file write): 59.802 s\n",
      "Total elapsed (including re-init): 59.810 s\n",
      "\n",
      "--- Measuring with 2 CPU(s) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 22:07:35,629\tINFO worker.py:1752 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time (excluding file write): 33.104 s\n",
      "Total elapsed (including re-init): 33.110 s\n",
      "\n",
      "--- Measuring with 3 CPU(s) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 22:08:14,693\tINFO worker.py:1752 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time (excluding file write): 25.291 s\n",
      "Total elapsed (including re-init): 25.298 s\n",
      "\n",
      "--- Measuring with 4 CPU(s) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 22:08:46,121\tINFO worker.py:1752 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time (excluding file write): 20.944 s\n",
      "Total elapsed (including re-init): 20.948 s\n",
      "\n",
      "CPU scaling summary:\n",
      " CPUs=1: 59.810s  speedup=1.00x\n",
      " CPUs=2: 33.110s  speedup=1.81x\n",
      " CPUs=3: 25.298s  speedup=2.36x\n",
      " CPUs=4: 20.948s  speedup=2.86x\n"
     ]
    }
   ],
   "source": [
    "def measure_cpu_scaling(path, cpus=(1, 2, 3, 4)):\n",
    "    \"\"\"Measure run_task2 runtime with different Ray CPU counts.\n",
    "\n",
    "    This re-initializes Ray/Modin for each CPU count, runs the same pipeline, and\n",
    "    records wall-clock time. It prints per-CPU times and speedups relative to 1 CPU.\n",
    "    \"\"\"\n",
    "    timings = {}\n",
    "    for c in cpus:\n",
    "        print(f\"\\n--- Measuring with {c} CPU(s) ---\")\n",
    "        try:\n",
    "            ray.shutdown()\n",
    "        except Exception:\n",
    "            pass\n",
    "        # reload Modin to pick up the new Ray init\n",
    "        try:\n",
    "            reload_modin()\n",
    "        except Exception:\n",
    "            pass\n",
    "        ray.init(num_cpus=c)\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        # run_task2 prints its own processing time; we measure end-to-end here\n",
    "        _ = run_task2(path)\n",
    "        t1 = time.perf_counter()\n",
    "        elapsed = t1 - t0\n",
    "        timings[c] = elapsed\n",
    "        print(f\"Total elapsed (including re-init): {elapsed:.3f} s\")\n",
    "\n",
    "    # summarize\n",
    "    base = timings.get(cpus[0], None)\n",
    "    print(\"\\nCPU scaling summary:\")\n",
    "    for c in cpus:\n",
    "        e = timings[c]\n",
    "        if base and base > 0:\n",
    "            speedup = base / e\n",
    "        else:\n",
    "            speedup = float('nan')\n",
    "        print(f\" CPUs={c}: {e:.3f}s  speedup={speedup:.2f}x\")\n",
    "\n",
    "    return timings\n",
    "\n",
    "# If run interactively, run the measurement for 1-4 CPUs and print results.\n",
    "try:\n",
    "    _ = measure_cpu_scaling(raw_dataset_path, cpus=(1, 2, 3, 4))\n",
    "except Exception:\n",
    "    # measurement is optional; if it fails in your environment, ignore and continue\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564dd8d-e178-4b8a-b7ed-a92593bd0033",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4f89e2b36b4c13ad7dc538be95abeba",
     "grade": true,
     "grade_id": "cell-92afcb7261e6540b",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The speedup is not linear (ideal would be 4× at 4 CPUs). Using Amdahl’s-law style reasoning, the observed speedups imply ≈86–90% of the workload is parallelizable; the remaining serial fraction, plus scheduling/serialization and I/O overheads, limit scaling. \n",
    "\n",
    "In practice the following factors cause the sub-linear speedup:\n",
    "1. Non-parallel work (I/O, CSV parsing, small serial steps) — Amdahl’s law limits maximum speedup.\n",
    "2. Ray/Modin overheads (task scheduling, serialization/deserialization, actor startup).\n",
    "3. Data skew and partition imbalance (some partitions/partitions take longer → stragglers).\n",
    "4. Resource contention (disk bandwidth, memory pressure, GC) when adding workers.\n",
    "\n",
    "Practical takeaway: expect sub-linear but meaningful speedups; to improve scaling, profile the pipeline, minimize serialization and small tasks, tune partitioning, and avoid re-initializing Ray in the timed loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f11961a-905b-4c4f-bb46-8b7b862de72b",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "#### Task 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3993703c-e62f-46e8-91d1-ec170e91de0b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7facd796d86f07184d829f936175f454",
     "grade": false,
     "grade_id": "cell-464b5a0a19c47bb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 22:21:56,105\tINFO worker.py:1752 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plain merge sort algorithm \n",
    "\"\"\"\n",
    "import heapq\n",
    "from typing import List\n",
    "import time\n",
    "import ray\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "num_workers = 4\n",
    "ray.shutdown()\n",
    "ray.init(num_cpus=num_workers)\n",
    "\n",
    "def merge(sublists: List[list]) -> list:\n",
    "    \"\"\"\n",
    "    Merge sorted sublists into a single sorted list.\n",
    "\n",
    "    :param sublists: List of sorted lists\n",
    "    :return: Merged result\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    sublists = [sublist for sublist in sublists if len(sublist)> 0]\n",
    "    heap = [(sublist[0], i, 0) for i, sublist in enumerate(sublists)]\n",
    "    heapq.heapify(heap)\n",
    "    while len(heap):\n",
    "        val, i, list_ind = heapq.heappop(heap)\n",
    "        result.append(val)\n",
    "        if list_ind+1 < len(sublists[i]):\n",
    "            heapq.heappush(heap, (sublists[i][list_ind+1], i, list_ind+1))\n",
    "    return result\n",
    "\n",
    "def plain_merge_sort(collection: list, npartitions: int = 4) -> list:\n",
    "    \"\"\"\n",
    "    Sorts a list using the merge sort algorithm. Breaks the list into multiple partitions.\n",
    "\n",
    "    :param collection: A mutable ordered collection with comparable items.\n",
    "    :return: The same collection ordered in ascending order.\n",
    "\n",
    "    Time Complexity: O(n log n)\n",
    "\n",
    "    Examples:\n",
    "    >>> merge_sort([0, 5, 3, 2, 2])\n",
    "    [0, 2, 2, 3, 5]\n",
    "    >>> merge_sort([])\n",
    "    []\n",
    "    >>> merge_sort([-2, -5, -45])\n",
    "    [-45, -5, -2]\n",
    "\n",
    "    Modified from: https://github.com/TheAlgorithms/Python/\n",
    "    \"\"\"\n",
    "\n",
    "    if len(collection) < npartitions:\n",
    "        return sorted(collection)\n",
    "    breaks = [i*len(collection)//npartitions for i in range(npartitions)]\n",
    "    breaks.append(len(collection))\n",
    "    sublists = [collection[breaks[i]:breaks[i+1]] for i in range(len(breaks)-1)]\n",
    "    sorted_sublists = [plain_merge_sort(sublist, npartitions=2) for sublist in sublists] # just use 2 partitions in recursive calls\n",
    "    return merge(sorted_sublists)\n",
    "\n",
    "@ray.remote\n",
    "def ray_merge_sort(collection, pair, npartitions):\n",
    "    return plain_merge_sort(collection[pair[0]:pair[1]], npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5dcac7b-bb51-4f99-9773-9cc9e9af1f27",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f099b3075af9881b2ffe8138d263a43",
     "grade": false,
     "grade_id": "cell-9f98e590bf91b999",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def merge_sort_ray(collection_ref: ray.ObjectRef, length: int, npartitions: int = 4) -> list:\n",
    "    \"\"\"\n",
    "    Merge sort with ray\n",
    "    \"\"\"\n",
    "    ## DO NOT MODIFY: START    \n",
    "    breaks = [i*length//npartitions for i in range(npartitions)]\n",
    "    breaks.append(length)\n",
    "    # Keep track of partition end points\n",
    "    sublist_end_points = [(breaks[i], breaks[i+1]) for i in range(len(breaks)-1)]\n",
    "    ## DO NOT MODIFY: END\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # Launch Ray tasks for each partition\n",
    "    futures = [\n",
    "        ray_merge_sort.remote(collection_ref, pair, npartitions)\n",
    "        for pair in sublist_end_points\n",
    "    ]\n",
    "    sorted_sublists = ray.get(futures)\n",
    "    # Pass your list of sorted sublists to `merge`\n",
    "    return merge(sorted_sublists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00d062c9-985a-48cc-8c40-20960bb756ed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bffc4f4b06298de874c802d247af3e0f",
     "grade": true,
     "grade_id": "cell-695d6f8d5e9a93e2",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain sorting: 15.175149202346802\n",
      "Ray sorting: 9.113381385803223\n",
      "Speedup:  1.6651502400620004\n"
     ]
    }
   ],
   "source": [
    "# We will be testing your code for a list of size 10M. Feel free to edit this for debugging. \n",
    "list1 = list(np.random.randint(low=0, high=1000, size=2_000_000))\n",
    "list2 = [c for c in list1] # make a copy\n",
    "length = len(list2)\n",
    "list2_ref = ray.put(list2) # insert into the driver's object store\n",
    "\n",
    "start1 = time.time()\n",
    "list1 = plain_merge_sort(list1, npartitions=num_workers)\n",
    "end1 = time.time()\n",
    "time_baseline = end1 - start1\n",
    "print(\"Plain sorting:\", time_baseline)\n",
    "\n",
    "start2 = time.time()\n",
    "list2 = merge_sort_ray(collection_ref=list2_ref, length=length, npartitions=num_workers)\n",
    "end2 = time.time()\n",
    "time_ray = end2 - start2\n",
    "print(\"Ray sorting:\", time_ray)\n",
    "\n",
    "speedup = time_baseline / time_ray\n",
    "print(\"Speedup: \", speedup)\n",
    "# Save timing metrics to JSON\n",
    "results = {\n",
    "    \"time_baseline\": time_baseline,\n",
    "    \"time_ray\": time_ray,\n",
    "    \"speedup\": speedup\n",
    "}\n",
    "assert sorted(list1) == list2, \"Sorted lists are not equal\"\n",
    "assert speedup > 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa5bbf-b2b1-41c1-8423-357aec5ff0aa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "639b699e307ea5285f5e74ef1880b1db",
     "grade": false,
     "grade_id": "cell-0048da95939f323d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Task 3.2\n",
    "The ideal speedup you can get for a task with 4 workers is, of course, 4. Can you estimate the theoretical maximum speedup you can get for the above merge sort algorithm (in terms of the time for sorting sublists, and the time for merging)? How do you account for the difference between the theoretical result and the observed speedup with Ray?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f6e91-5f4f-4a95-986b-5c68abdf40ca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea54f668c59b2be4a96999da24d2428c",
     "grade": true,
     "grade_id": "cell-6362a0cee0945609",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. Theoretical maximum speedup for this algorithm:\n",
    "\n",
    "- If T_sort is the (parallelizable) time to sort sublists and T_merge is the (serial) time to merge them, serial time = T_sort + T_merge.\n",
    "With perfect parallelism (p workers), ideal time ≈ T_sort/p + T_merge. So maximum speedup as p→∞ is:\n",
    "- S_max = (T_sort + T_merge)/T_merge = 1 + T_sort/T_merge = 1 + P/(1−P).\n",
    "- P ≈ 0.53 gives S_max ≈ 1 + 0.53/0.47 ≈ 2.14, so even with infinite parallel sorting capacity, the algorithm (as implemented) cannot exceed ≈2.14× speedup because merging is a substantial fraction (~47%) of the serial time.\n",
    "\n",
    "2. Accounting for the difference to the observed speedup:\n",
    "- The merge phase T_merge is serial in our implementation (final heap-merge on the driver), so it limits speedup by Amdahl’s law. Even with perfect parallel sorting, we cannot exceed 1 + T_sort/T_merge.\n",
    "- Practical overheads (scheduling, serialization, data movement, object copies, driver-side merge work, load imbalance, GC and memory pressure, I/O) further reduce observed speedup below the ideal S(p)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Training and Tuning with Ray\n",
    "\n",
    "## Part 1: Training with Ray Train and Xgboost\n",
    "In this task, you will train a machine learning model using the preprocessed data. The goal is to train an Xgboost model to predict the user rating for a product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ray==2.50.0 --quiet\n",
    "# !pip install xgboost==1.7.6 --quiet\n",
    "# !pip install -U tensorboardx --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df5022c23fe644f2bee2fc014e8f63cb",
     "grade": false,
     "grade_id": "cell-1afacb47f39fb5ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:44,977\tINFO worker.py:2004 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "/home/wew068/.local/lib/python3.11/site-packages/ray/_private/worker.py:2052: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m - (node_id=68b8eea9288f716a1d135c3f1856321e6a4d3ecbe0672f1ef55cd21a, ip=10.32.73.154, pid=42910) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=42910)\u001b[0m [22:33:54] task [xgboost.ray-rank=00000000]:eb8829f4171ce3dc05d976a501000000 got new rank 0\n",
      "\u001b[36m(SplitCoordinator pid=43041)\u001b[0m Registered dataset logger for dataset train_1_0\n",
      "\u001b[36m(SplitCoordinator pid=43041)\u001b[0m Starting execution of Dataset train_1_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=43041)\u001b[0m Execution plan of Dataset train_1_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=43041)\u001b[0m ✔️  Dataset train_1_0 execution finished in 2.48 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m [0]\ttrain-rmse:2.79975\n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m [1]\ttrain-rmse:2.11608\n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m [2]\ttrain-rmse:1.68245\n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m [3]\ttrain-rmse:1.42241\n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m [4]\ttrain-rmse:1.27567\n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m [5]\ttrain-rmse:1.19713\n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m [6]\ttrain-rmse:1.15659\n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m [7]\ttrain-rmse:1.13610\n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m [8]\ttrain-rmse:1.12581\n",
      "\u001b[36m(XGBoostTrainer pid=42707)\u001b[0m [9]\ttrain-rmse:1.12071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=42910)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-33-48/XGBoostTrainer_fb7d8_00000_0_2025-11-20_22-33-50/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=42910)\u001b[0m Registered dataset logger for dataset dataset_3_0\n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m - (node_id=68b8eea9288f716a1d135c3f1856321e6a4d3ecbe0672f1ef55cd21a, ip=10.32.73.154, pid=44887) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=44887)\u001b[0m [22:57:00] task [xgboost.ray-rank=00000000]:a1ca4b2421989f82908eab7501000000 got new rank 0\n",
      "\u001b[36m(SplitCoordinator pid=45016)\u001b[0m Registered dataset logger for dataset train_9_0\n",
      "\u001b[36m(SplitCoordinator pid=45016)\u001b[0m Starting execution of Dataset train_9_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=45016)\u001b[0m Execution plan of Dataset train_9_0: InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=45016)\u001b[0m ✔️  Dataset train_9_0 execution finished in 0.43 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m [0]\ttrain-rmse:2.79972\tvalidation-rmse:2.79912\n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m [1]\ttrain-rmse:2.11589\tvalidation-rmse:2.11562\n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m [2]\ttrain-rmse:1.68215\tvalidation-rmse:1.68226\n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m [3]\ttrain-rmse:1.42199\tvalidation-rmse:1.42251\n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m [4]\ttrain-rmse:1.27514\tvalidation-rmse:1.27600\n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m [5]\ttrain-rmse:1.19658\tvalidation-rmse:1.19771\n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m [6]\ttrain-rmse:1.15603\tvalidation-rmse:1.15737\n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m [7]\ttrain-rmse:1.13557\tvalidation-rmse:1.13707\n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m [8]\ttrain-rmse:1.12528\tvalidation-rmse:1.12684\n",
      "\u001b[36m(XGBoostTrainer pid=44755)\u001b[0m [9]\ttrain-rmse:1.12009\tvalidation-rmse:1.12173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=44887)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-56-55/XGBoostTrainer_35e72_00000_0_eta=0.3000,max_depth=3_2025-11-20_22-56-55/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=44887)\u001b[0m Registered dataset logger for dataset dataset_14_0\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(SplitCoordinator pid=45017)\u001b[0m Starting execution of Dataset validation_11_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=45017)\u001b[0m Execution plan of Dataset validation_11_0: InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=45017)\u001b[0m ✔️  Dataset validation_11_0 execution finished in 0.18 seconds\n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m - (node_id=68b8eea9288f716a1d135c3f1856321e6a4d3ecbe0672f1ef55cd21a, ip=10.32.73.154, pid=45443) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=45443)\u001b[0m [22:57:18] task [xgboost.ray-rank=00000000]:20e1e23a11985d614234bf2701000000 got new rank 0\n",
      "\u001b[36m(SplitCoordinator pid=45573)\u001b[0m Registered dataset logger for dataset train_15_0\n",
      "\u001b[36m(SplitCoordinator pid=45573)\u001b[0m Starting execution of Dataset train_15_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=45573)\u001b[0m Execution plan of Dataset train_15_0: InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=45573)\u001b[0m ✔️  Dataset train_15_0 execution finished in 0.41 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m [0]\ttrain-rmse:2.14718\tvalidation-rmse:2.14683\n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m [1]\ttrain-rmse:1.44490\tvalidation-rmse:1.44534\n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m [2]\ttrain-rmse:1.20686\tvalidation-rmse:1.20795\n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m [3]\ttrain-rmse:1.13931\tvalidation-rmse:1.14080\n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m [4]\ttrain-rmse:1.12156\tvalidation-rmse:1.12324\n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m [5]\ttrain-rmse:1.11696\tvalidation-rmse:1.11872\n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m [6]\ttrain-rmse:1.11558\tvalidation-rmse:1.11736\n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m [7]\ttrain-rmse:1.11514\tvalidation-rmse:1.11694\n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m [8]\ttrain-rmse:1.11470\tvalidation-rmse:1.11649\n",
      "\u001b[36m(XGBoostTrainer pid=45311)\u001b[0m [9]\ttrain-rmse:1.11442\tvalidation-rmse:1.11627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=45443)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-56-55/XGBoostTrainer_35e72_00001_1_eta=0.5000,max_depth=3_2025-11-20_22-57-13/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=45443)\u001b[0m Registered dataset logger for dataset dataset_20_0\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(SplitCoordinator pid=45574)\u001b[0m Starting execution of Dataset validation_17_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=45574)\u001b[0m Execution plan of Dataset validation_17_0: InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=45574)\u001b[0m ✔️  Dataset validation_17_0 execution finished in 0.16 seconds\n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m - (node_id=68b8eea9288f716a1d135c3f1856321e6a4d3ecbe0672f1ef55cd21a, ip=10.32.73.154, pid=45995) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=45995)\u001b[0m [22:57:36] task [xgboost.ray-rank=00000000]:836b8587206734f83620991001000000 got new rank 0\n",
      "\u001b[36m(SplitCoordinator pid=46126)\u001b[0m Registered dataset logger for dataset train_21_0\n",
      "\u001b[36m(SplitCoordinator pid=46126)\u001b[0m Starting execution of Dataset train_21_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=46126)\u001b[0m Execution plan of Dataset train_21_0: InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=46126)\u001b[0m ✔️  Dataset train_21_0 execution finished in 0.43 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m [0]\ttrain-rmse:2.79953\tvalidation-rmse:2.79897\n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m [1]\ttrain-rmse:2.11524\tvalidation-rmse:2.11504\n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m [2]\ttrain-rmse:1.68094\tvalidation-rmse:1.68119\n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m [3]\ttrain-rmse:1.42031\tvalidation-rmse:1.42099\n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m [4]\ttrain-rmse:1.27271\tvalidation-rmse:1.27380\n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m [5]\ttrain-rmse:1.19356\tvalidation-rmse:1.19496\n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m [6]\ttrain-rmse:1.15248\tvalidation-rmse:1.15412\n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m [7]\ttrain-rmse:1.13184\tvalidation-rmse:1.13365\n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m [8]\ttrain-rmse:1.12122\tvalidation-rmse:1.12316\n",
      "\u001b[36m(XGBoostTrainer pid=45865)\u001b[0m [9]\ttrain-rmse:1.11575\tvalidation-rmse:1.11781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=45995)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-56-55/XGBoostTrainer_35e72_00002_2_eta=0.3000,max_depth=5_2025-11-20_22-57-32/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=45995)\u001b[0m Registered dataset logger for dataset dataset_26_0\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(SplitCoordinator pid=46127)\u001b[0m Starting execution of Dataset validation_23_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=46127)\u001b[0m Execution plan of Dataset validation_23_0: InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=46127)\u001b[0m ✔️  Dataset validation_23_0 execution finished in 0.13 seconds\n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m - (node_id=68b8eea9288f716a1d135c3f1856321e6a4d3ecbe0672f1ef55cd21a, ip=10.32.73.154, pid=46548) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=46548)\u001b[0m [22:57:54] task [xgboost.ray-rank=00000000]:f6102f340760816c3ba937c101000000 got new rank 0\n",
      "\u001b[36m(SplitCoordinator pid=46678)\u001b[0m Registered dataset logger for dataset train_27_0\n",
      "\u001b[36m(SplitCoordinator pid=46678)\u001b[0m Starting execution of Dataset train_27_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=46678)\u001b[0m Execution plan of Dataset train_27_0: InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=46678)\u001b[0m ✔️  Dataset train_27_0 execution finished in 0.50 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m [0]\ttrain-rmse:2.14681\tvalidation-rmse:2.14654\n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m [1]\ttrain-rmse:1.44358\tvalidation-rmse:1.44410\n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m [2]\ttrain-rmse:1.20447\tvalidation-rmse:1.20574\n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m [3]\ttrain-rmse:1.13627\tvalidation-rmse:1.13804\n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m [4]\ttrain-rmse:1.11819\tvalidation-rmse:1.12012\n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m [5]\ttrain-rmse:1.11277\tvalidation-rmse:1.11486\n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m [6]\ttrain-rmse:1.11108\tvalidation-rmse:1.11337\n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m [7]\ttrain-rmse:1.10987\tvalidation-rmse:1.11221\n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m [8]\ttrain-rmse:1.10893\tvalidation-rmse:1.11136\n",
      "\u001b[36m(XGBoostTrainer pid=46417)\u001b[0m [9]\ttrain-rmse:1.10832\tvalidation-rmse:1.11088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=46548)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-56-55/XGBoostTrainer_35e72_00003_3_eta=0.5000,max_depth=5_2025-11-20_22-57-49/checkpoint_000000)\n",
      "\u001b[36m(RayTrainWorker pid=46548)\u001b[0m Registered dataset logger for dataset dataset_32_0\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(SplitCoordinator pid=46677)\u001b[0m Starting execution of Dataset validation_29_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=46677)\u001b[0m Execution plan of Dataset validation_29_0: InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=46677)\u001b[0m ✔️  Dataset validation_29_0 execution finished in 0.15 seconds\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import psutil\n",
    "ray.shutdown()\n",
    "NINE_GIB = 9 * 1024 * 1024 * 1024\n",
    "ray.init(object_store_memory=int(NINE_GIB))\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "seed = 41\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.train import ScalingConfig, RunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8f196b1e162122bd6644aa2d9b68ee6",
     "grade": false,
     "grade_id": "cell-f3aaff711b26826e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6617a6bf984542a1a969fd0e1791b859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parquet dataset sampling 0:   0%|          | 0.00/1.00 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:48,082\tINFO parquet_datasource.py:699 -- Estimated parquet encoding ratio is 4.203.\n",
      "2025-11-20 22:33:48,084\tINFO parquet_datasource.py:759 -- Estimated parquet reader batch size at 677868 rows\n"
     ]
    }
   ],
   "source": [
    "# load the preprocessed dataset as dense vectors in the parquet format\n",
    "train_data_path=os.path.expanduser(\"~/public/pa3/ml_features_train.parquet\")\n",
    "train_data = ray.data.read_parquet(train_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Train a regression model (MSE objective) to predict `overall` using `XGBoostTrainer`.\n",
    "- Objective: regression with squared error (`reg:squarederror`)\n",
    "- Model params: `max_depth=3`, `eta=0.3`, others default.\n",
    "- Use Ray Train with a suitable `ScalingConfig`; and you can set 2 CPUs per worker.\n",
    "- After training, run inference on the test set.\n",
    "\n",
    "Note: Ray will by default try to store results in `~/ray_results`. This can throw permission errors in DataHub, so you can change the location to `~/private/ray_results` using [RunConfig](https://docs.ray.io/en/latest/train/api/doc/ray.train.RunConfig.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7313f041c72e0fb8bd16b8f7eafd3c0d",
     "grade": false,
     "grade_id": "cell-75f2ec9ff54d45a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create the XGBoost trainer for regression on the \"overall\" label using the built-in trainer\n",
    "import xgboost as xgb\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    label_column=\"overall\",\n",
    "    params={\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"max_depth\": 3,\n",
    "        \"eta\": 0.3,\n",
    "    },\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=1,\n",
    "        use_gpu=False,\n",
    "        resources_per_worker={\"CPU\": 2},\n",
    "    ),\n",
    "    run_config=RunConfig(storage_path=\"~/private/ray_results\"),\n",
    "    datasets={\"train\": train_data},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a230c4dedf24b68848843be1b27fd455",
     "grade": false,
     "grade_id": "cell-61e3317c4d6fa5cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:48,689\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-11-20 22:33:50 (running for 00:00:00.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-11-20_22-33-41_618501_40643/artifacts/2025-11-20_22-33-48/XGBoostTrainer_2025-11-20_22-33-48/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-11-20 22:33:55 (running for 00:00:05.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-11-20_22-33-41_618501_40643/artifacts/2025-11-20_22-33-48/XGBoostTrainer_2025-11-20_22-33-48/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4981b6ef80c48a68077e3c7878b95d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=43041) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bfb0576a4f479b8b2baf81c23d810e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=43041) - ReadParquet->SplitBlocks(100) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d964b1a02e4e288dcb9963cc174cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=43041) - split(1, equal=True) 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-11-20 22:34:00 (running for 00:00:10.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-11-20_22-33-41_618501_40643/artifacts/2025-11-20_22-33-48/XGBoostTrainer_2025-11-20_22-33-48/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-11-20 22:34:05 (running for 00:00:15.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-11-20_22-33-41_618501_40643/artifacts/2025-11-20_22-33-48/XGBoostTrainer_2025-11-20_22-33-48/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:34:08,612\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-33-48' in 0.0087s.\n",
      "2025-11-20 22:34:08,615\tINFO tune.py:1041 -- Total run time: 19.93 seconds (18.34 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-11-20 22:34:08 (running for 00:00:18.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-11-20_22-33-41_618501_40643/artifacts/2025-11-20_22-33-48/XGBoostTrainer_2025-11-20_22-33-48/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a700590a1bc5d8674f398f3b04d28bc0",
     "grade": false,
     "grade_id": "cell-47e03c388b83264b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(\n",
      "  metrics={'train-rmse': 1.120708220781679},\n",
      "  path='/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-33-48/XGBoostTrainer_fb7d8_00000_0_2025-11-20_22-33-50',\n",
      "  filesystem='local',\n",
      "  checkpoint=Checkpoint(filesystem=local, path=/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-33-48/XGBoostTrainer_fb7d8_00000_0_2025-11-20_22-33-50/checkpoint_000000)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing test data performance\n",
    "\n",
    "Next, use the trained model to generate predictions on test data. Calculate the root mean square error (RMSE) of\n",
    "the test predictions and report it in the output. \n",
    "\n",
    "For this task, we will make use of [`map_batches`](https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.map_batches.html) to make a stateful transformation of the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d889ae825c1d534d93219cfc53539ebb",
     "grade": false,
     "grade_id": "cell-7ca4c61c876a650a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176ef2c209454f94af4386d423522220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parquet dataset sampling 0:   0%|          | 0.00/1.00 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:34:08,733\tINFO parquet_datasource.py:699 -- Estimated parquet encoding ratio is 3.786.\n",
      "2025-11-20 22:34:08,734\tINFO parquet_datasource.py:759 -- Estimated parquet reader batch size at 677868 rows\n"
     ]
    }
   ],
   "source": [
    "test_data_path=os.path.expanduser(\"~/public/pa3/ml_features_test.parquet\")\n",
    "test_dataset= ray.data.read_parquet(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f7f2f27524a6fc65f24b850395d8490",
     "grade": false,
     "grade_id": "cell-72d7a953e71ec875",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = trainer.get_model(result.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebea4e4c524dc3fd2a5531b418cb2c81",
     "grade": false,
     "grade_id": "cell-fd7e85b107f63b98",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ray.train import Checkpoint\n",
    "import xgboost\n",
    "import math\n",
    "\n",
    "class Predictor:\n",
    "\n",
    "    def __init__(self, checkpoint: Checkpoint):\n",
    "        # Load model from the provided checkpoint\n",
    "        self.model = XGBoostTrainer.get_model(checkpoint)\n",
    "        self.label_col = \"overall\"\n",
    "\n",
    "    def __call__(self, batch: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        1. Get the predictions on a batch of data for an xgboost model.\n",
    "        2. Return the squared errors for each entry using the label column\n",
    "        \"\"\"\n",
    "        batch_features, batch_labels =  batch.loc[:, batch.columns != self.label_col], batch[[self.label_col]]\n",
    "        dmatrix = xgboost.DMatrix(batch_features)\n",
    "        batch[\"predictions\"] = self.model.predict(dmatrix)\n",
    "        errors = (batch[\"predictions\"] - batch_labels[self.label_col])**2\n",
    "        return {\"se\": errors}\n",
    "\n",
    "def predict_xgboost(test_dataset, result):\n",
    "    \"\"\"\n",
    "    Obtains the predictions for a test dataset given a `ray.train.Result` object and returns the squared errors for each entry\n",
    "    Hint: ds.map_batches()\n",
    "    \"\"\"\n",
    "    # create predictor from the result checkpoint\n",
    "    predictor = Predictor(result.checkpoint)\n",
    "\n",
    "    # apply predictor to test dataset (batch-wise) and collect squared errors\n",
    "    se_ds = test_dataset.map_batches(predictor, batch_format=\"pandas\")\n",
    "    se_df = se_ds.to_pandas()\n",
    "\n",
    "    # return squared errors as a 1-D numpy array\n",
    "    squared_errors = se_df[\"se\"].to_numpy()\n",
    "    return squared_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8617498359e55c4994fb5a757e838e15",
     "grade": false,
     "grade_id": "cell-709a7156a1c24be1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:34:09,895\tINFO logging.py:293 -- Registered dataset logger for dataset dataset_5_0\n",
      "2025-11-20 22:34:09,926\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_5_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "2025-11-20 22:34:09,927\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_5_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(Predictor)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af90cf77be24fa09bccc57ddf66d3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f867a70cb4b37a015aa2e337be677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadParquet->SplitBlocks(75) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f15fcc7f99a44a6b37f9671d8d53760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(Predictor) 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:34:13,539\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_5_0 execution finished in 3.61 seconds\n"
     ]
    }
   ],
   "source": [
    "# get the root mean squared error for the test dataset using the result.\n",
    "# Save the test rmse in `test_rmse` \n",
    "\n",
    "# Use the predictor implemented earlier to get squared errors, then compute RMSE\n",
    "squared_errors = predict_xgboost(test_dataset, result)\n",
    "test_rmse = float(np.sqrt(np.mean(squared_errors)))\n",
    "\n",
    "# write to file\n",
    "res_2_1 = {\"test_rmse\": test_rmse, \n",
    "          \"train_rmse\": result.metrics[\"train-rmse\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afb535a4844958198e8e2158ed6e243f",
     "grade": true,
     "grade_id": "cell-26a7991b985e5a27",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 2.1 output matches expected within ±0.01 for RMSE.\n"
     ]
    }
   ],
   "source": [
    "expected_path = Path(\"~/public/pa3/expected_2_1.json\").expanduser()\n",
    "with open(expected_path) as expected_file:\n",
    "    expected = json.load(expected_file)\n",
    "\n",
    "assert math.isclose(float(expected[\"train_rmse\"]), float(res_2_1[\"train_rmse\"]), abs_tol=0.01), \\\n",
    "    f\"train_rmse mismatch: expected {expected['train_rmse']} vs {res_2_1['train_rmse']} (±0.01)\"\n",
    "\n",
    "assert math.isclose(float(expected[\"test_rmse\"]), float(res_2_1[\"test_rmse\"]), abs_tol=0.01), \\\n",
    "    f\"test_rmse mismatch: expected {expected['test_rmse']} vs {res_2_1['test_rmse']} (±0.01)\"\n",
    "\n",
    "print(\"✅ Task 2.1 output matches expected within ±0.01 for RMSE.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Tuning with Ray Tune\n",
    "\n",
    "Based on `XGBoostTrainer` you just implemented, now We'll tune the following hyperparameters:\n",
    "\n",
    "1. `max_depth`\n",
    "2. `eta`\n",
    "\n",
    "You can read more about each hyperparameter in the [official docs](https://xgboost.readthedocs.io/en/stable/parameter.html). Since the overall search space is large, and our compute budget is limited, we'll focus on running 4 *trials* (or 4 instances of 2-tuples of hyperparameters) with a grid search.  Here are the values:\n",
    "\n",
    "1. `max_depth`: $[3, 5]$ \n",
    "2. `eta`: $[0.3, 0.5]$\n",
    "\n",
    "Steps to implement, repeated from the problem statement:\n",
    "1. Create a new training and validation data from the original training data - with a random split of 75/25.\n",
    "2. Train Xgboost models with 4 hyperparameter trials over the given grid using Ray Tune. [Offical Example](https://docs.ray.io/en/latest/tune/examples/tune-xgboost.html)\n",
    "3. Select the best model with the lowest validation RMSE. \n",
    "4. Report the test RMSE for the best model and the lowest validation RMSE.\n",
    "\n",
    "Make sure to use the same `ScalingConfig` as before. Restrict the number of concurrent trials to 1 for memory efficiency. Store the final `tune.ResultGrid` object in `result_grid` and the best result in the variable `best_result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40df9ed8904939f427098a20c8835dcd",
     "grade": false,
     "grade_id": "cell-274485071ae6e581",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-11-20 22:58:08</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:13.11        </td></tr>\n",
       "<tr><td>Memory:      </td><td>55.4/503.7 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  params/eta</th><th style=\"text-align: right;\">  params/max_depth</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-rmse</th><th style=\"text-align: right;\">  validation-rmse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_35e72_00000</td><td>TERMINATED</td><td>10.32.73.154:44755</td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         13.764 </td><td style=\"text-align: right;\">     1.12009</td><td style=\"text-align: right;\">          1.12173</td></tr>\n",
       "<tr><td>XGBoostTrainer_35e72_00001</td><td>TERMINATED</td><td>10.32.73.154:45311</td><td style=\"text-align: right;\">         0.5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         14.8285</td><td style=\"text-align: right;\">     1.11442</td><td style=\"text-align: right;\">          1.11627</td></tr>\n",
       "<tr><td>XGBoostTrainer_35e72_00002</td><td>TERMINATED</td><td>10.32.73.154:45865</td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         13.6959</td><td style=\"text-align: right;\">     1.11575</td><td style=\"text-align: right;\">          1.11781</td></tr>\n",
       "<tr><td>XGBoostTrainer_35e72_00003</td><td>TERMINATED</td><td>10.32.73.154:46417</td><td style=\"text-align: right;\">         0.5</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         15.0593</td><td style=\"text-align: right;\">     1.10832</td><td style=\"text-align: right;\">          1.11088</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df69cae5de547e4a075576525bbcf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=45016) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bdd57cfffe4149a29f1018eda1f0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=45016) - split(1, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e3b2260a8d4b8bacc8447357e7386f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=45017) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8f0aeaee614f428b73c41ed7d4cd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=45017) - split(1, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe977ef61cfd4b0b8e790f60db0d19b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=45573) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd56bfd22613485f89064cf070698b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=45573) - split(1, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4c511cc89847cfbe2d14805f362224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=45574) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b2766d4fe345a589c6f5efec54172d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=45574) - split(1, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b9ec2dbcac4cd59305ffcc45d6ecfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=46126) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9877e538f0a14b3a90adf08918724600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=46126) - split(1, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2035a4516944ba897d6488466c1ac8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=46127) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac1285a70584e30aacfdded11ffb71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=46127) - split(1, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9135f5d6754e4d218648448abebca3f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=46678) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdaaf9e714f14182950c1f104c06f0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=46678) - split(1, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a31c0ad26bd4a55b57000b3ed610722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=46677) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ce0a9c66af4770b8509305b2e91fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=46677) - split(1, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:58:08,299\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-56-55' in 0.0363s.\n",
      "2025-11-20 22:58:08,303\tINFO tune.py:1041 -- Total run time: 73.12 seconds (73.07 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "# store your answers in these\n",
    "best_result = None\n",
    "result_grid = None\n",
    "\n",
    "# Split the dataset into training and validation sets (75/25 split)\n",
    "train_ds, valid_ds = train_data.train_test_split(test_size=0.25, seed=seed)\n",
    "\n",
    "# Define the XGBoostTrainer with static configurations\n",
    "trainer = XGBoostTrainer(\n",
    "    label_column=\"overall\",\n",
    "    params={\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "    },\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=1,\n",
    "        use_gpu=False,\n",
    "        resources_per_worker={\"CPU\": 2},\n",
    "    ),\n",
    "    run_config=RunConfig(storage_path=\"~/private/ray_results\"),\n",
    "    datasets={\"train\": train_ds, \"validation\": valid_ds},\n",
    ")\n",
    "\n",
    "# Define the Tuner for hyperparameter grid search\n",
    "tuner = tune.Tuner(\n",
    "    trainer,\n",
    "    param_space={\n",
    "        \"params\": {\n",
    "            \"max_depth\": tune.grid_search([3, 5]),\n",
    "            \"eta\": tune.grid_search([0.3, 0.5]),\n",
    "        }\n",
    "    },\n",
    "    tune_config=tune.TuneConfig(\n",
    "        max_concurrent_trials=1,\n",
    "        metric=\"validation-rmse\",\n",
    "        mode=\"min\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Execute the tuning process\n",
    "result_grid = tuner.fit()\n",
    "\n",
    "# Retrieve the best result based on validation RMSE\n",
    "best_result = result_grid.get_best_result(metric=\"validation-rmse\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7de318b714149d5509382914115955e7",
     "grade": false,
     "grade_id": "cell-8d07bb72e4410338",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(\n",
      "  metrics={'train-rmse': 1.108322672118614, 'validation-rmse': 1.1108811485952415},\n",
      "  path='/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-56-55/XGBoostTrainer_35e72_00003_3_eta=0.5000,max_depth=5_2025-11-20_22-57-49',\n",
      "  filesystem='local',\n",
      "  checkpoint=Checkpoint(filesystem=local, path=/home/wew068/private/ray_results/XGBoostTrainer_2025-11-20_22-56-55/XGBoostTrainer_35e72_00003_3_eta=0.5000,max_depth=5_2025-11-20_22-57-49/checkpoint_000000)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6bf8c21b3b79eb1b2b6a21e71f8aa72",
     "grade": false,
     "grade_id": "cell-50f29ff46bfb2d7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, \n",
    "1. Get the root mean squared error for the test dataset using the best result from the hyperparameter tuning experiments.\n",
    "2. Report the validation rmse values for the best model as well as the given specific configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7eaed52e4fec4c70bdb5bfb97d1861d7",
     "grade": false,
     "grade_id": "cell-f729ed2a7b3039c6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_task_2_2_results(result_grid: tune.ResultGrid, best_result: ray.train.Result):\n",
    "    res = {\n",
    "        \"test_rmse\": None, # test rmse for the best model\n",
    "        \"valid_rmse\": None, # validation rmse for the best model\n",
    "        \"valid_depth_5_eta_0.3\": None, # validation rmse for max_depth=5, eta=0.3\n",
    "        \"valid_depth_3_eta_0.5\": None, # validation rmse for max_depth=3, eta=0.5\n",
    "    }\n",
    "\n",
    "    # compute test rmse using the supplied best_result\n",
    "    # best_result is a ray.train.Result - we can use its checkpoint to predict on the test set\n",
    "    test_se = predict_xgboost(test_dataset, best_result)\n",
    "    res['test_rmse'] = float(np.sqrt(np.mean(test_se)))\n",
    "\n",
    "    # validation rmse for best model\n",
    "    res['valid_rmse'] = float(best_result.metrics['validation-rmse'])\n",
    "\n",
    "    # helper: iterate over results in the result_grid and extract validation rmse for specific configs\n",
    "    # ResultGrid is iterable, yielding ray.train.Result-like objects\n",
    "    for r in result_grid:\n",
    "        # r.config may contain the nested 'params' mapping used by XGBoostTrainer\n",
    "        cfg = getattr(r, 'config', {}) or {}\n",
    "        params = cfg.get('params', {})\n",
    "        md = params.get('max_depth')\n",
    "        eta = params.get('eta')\n",
    "\n",
    "        valid = None\n",
    "        # metrics may be stored on r.metrics\n",
    "        if hasattr(r, 'metrics'):\n",
    "            valid = r.metrics.get('validation-rmse')\n",
    "        elif hasattr(r, 'result') and isinstance(r.result, dict):\n",
    "            valid = r.result.get('validation-rmse')\n",
    "\n",
    "        if md == 5 and eta == 0.3:\n",
    "            res['valid_depth_5_eta_0.3'] = float(valid)\n",
    "        if md == 3 and eta == 0.5:\n",
    "            res['valid_depth_3_eta_0.5'] = float(valid)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25afd3d4f65a0b3aa61f9b10c4e5078e",
     "grade": false,
     "grade_id": "cell-caf5fe6461b02dd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 23:02:38,392\tINFO logging.py:293 -- Registered dataset logger for dataset dataset_33_0\n",
      "2025-11-20 23:02:38,497\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_33_0. Full logs are in /tmp/ray/session_2025-11-20_22-33-41_618501_40643/logs/ray-data\n",
      "2025-11-20 23:02:38,498\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_33_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(Predictor)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debac6c6b4434167b1fe29e1bf27d2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bd929908ce4321bbeb73b7e53d2643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadParquet->SplitBlocks(75) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91648bced0774b56b2052abab6c798fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(Predictor) 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 23:02:40,273\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_33_0 execution finished in 1.77 seconds\n"
     ]
    }
   ],
   "source": [
    "res_2_2 = get_task_2_2_results(result_grid, best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d98c86cef5d1604e535408ad3bd19416",
     "grade": true,
     "grade_id": "cell-540519f28aa086b6",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task 2.2 output matches expected within ±0.01 for RMSE.\n"
     ]
    }
   ],
   "source": [
    "expected_path = Path(\"~/public/pa3/expected_2_2.json\").expanduser()\n",
    "with open(expected_path) as expected_file:\n",
    "    expected = json.load(expected_file)\n",
    "\n",
    "for key in res_2_2.keys():\n",
    "    assert math.isclose(float(expected[key]), float(res_2_2[key]), abs_tol=0.01), \\\n",
    "        f\"{key} mismatch: expected {expected[key]} vs {res_2_2[key]} (±0.01)\"\n",
    "\n",
    "print(\"✅ Task 2.2 output matches expected within ±0.01 for RMSE.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4839304491826befcc567edd4cdf027a",
     "grade": false,
     "grade_id": "cell-e49486e627c4fdec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# shutdown!\n",
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
